{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ModularCode_ProjectName.ipynb","provenance":[{"file_id":"16EZjYBjgr7GipB3czMY1kbmy9Vx6P-N7","timestamp":1608482128130}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"apbfZgi6ryhg"},"source":["**Installation of Required Packages**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGzsHbflyh0a","executionInfo":{"status":"ok","timestamp":1608556467910,"user_tz":-360,"elapsed":5399,"user":{"displayName":"Nishat Anjum","photoUrl":"","userId":"06823098873876595214"}},"outputId":"7f5f781f-be84-41aa-cfb1-9ed0991b40ed"},"source":["pip install biopython"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting biopython\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/02/8b606c4aa92ff61b5eda71d23b499ab1de57d5e818be33f77b01a6f435a8/biopython-1.78-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 7.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.19.4)\n","Installing collected packages: biopython\n","Successfully installed biopython-1.78\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kNyn8Ej1Z0yC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608556617663,"user_tz":-360,"elapsed":127066,"user":{"displayName":"Nishat Anjum","photoUrl":"","userId":"06823098873876595214"}},"outputId":"9a868d88-966b-4d53-9d89-4d0cd7b1200b"},"source":["import tensorflow as tf\r\n","from tensorflow import keras\r\n","from keras.models import Sequential\r\n","from keras.callbacks import ModelCheckpoint\r\n","from keras.optimizers import SGD, Adam, Adadelta, RMSprop\r\n","from keras.layers import Conv1D, Dense, MaxPooling1D, Flatten, Dropout, SpatialDropout1D\r\n","from keras.layers import Embedding, GlobalAveragePooling1D, LSTM, SimpleRNN, GRU, Bidirectional\r\n","from tensorflow.compat.v1.keras.layers import CuDNNLSTM\r\n","from keras.layers import Softmax\r\n","from google.colab import drive\r\n","from Bio import SeqIO\r\n","from Bio.Seq import Seq\r\n","import numpy as np \r\n","\r\n","\r\n","\r\n","drive.mount('/content/drive')\r\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m96WB6WuZuA5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608524952498,"user_tz":-360,"elapsed":218015,"user":{"displayName":"L Lawlight","photoUrl":"","userId":"13905760247926160423"}},"outputId":"0f5b6eee-c867-4756-ee0b-5d0364c2f362"},"source":["import pickle\n","from keras.preprocessing.text import Tokenizer\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","    \n","def getKmers(sequence, size):\n","    return [sequence[x:x+size].upper() for x in range(len(sequence) - size + 1)]\n","\n","def prepare_training_dataset(k,MOVE_WINDOW,READ_LEN, JUMP, WHOLE_SEQ, OUTPUTFILEPATH):\n","    # Any of the following is the selection criteria\n","    # Subtype with >=N samples\n","    # Top M subtypes.\n","    # k is the k-mer size\n","    # READ_LEN is the contig length for each data sample in the prepared dataset.\n","    # MOVE_WINDOW = 1 means moving the window every 'JUMP' number of charaters\n","    # MOVE_WINDOW = 0 does not mode the wondow. No use of JUMP in this case. \n","    \n","\n","    N=25\n","    M=25\n","    newnames={'B': 5727, 'C': 2077, '01_AE': 1426, 'A1': 498, '01B': 210, \n","                    '02_AG': 168, 'BF1': 143, 'A6': 117, 'A1C': 111, 'G': 96, 'BC': 95, \n","                    'A1D': 94, 'AD': 94, 'D': 87, 'F1': 82, 'A1CD': 62, 'CD': 61, 'O': 57,\n","                    '0107': 57, '01BC': 50, '07_BC': 41, '08_BC': 35, '02A1': 29, \n","                    '11_cpx': 25, '35_AD': 22}\n","\n","    subtype_seqs = {}\n","    \n","    type_seqs = {}\n","    type_texts = {}\n","    neucleotide_list = ['A','T','C','G']\n","    for key in newnames.keys(): \n","        type_seqs[key] = []\n","\n","        # You need to CHANGE the SUBTYPES FOLDER LOCATION according to your drive location. \n","        subtype = SeqIO.parse(open('/content/drive/MyDrive/ML 472/Data/subtypes/'+key+'.fasta','r'), 'fasta')\n","        \n","        for record in subtype:\n","            chars = set(record.seq)\n","            new_seq = str(record.seq)\n","            for c in chars:\n","                if c not in neucleotide_list:\n","                    new_seq = new_seq.replace(c,'')\n","\n","            if MOVE_WINDOW == 0:\n","                READ_LEN = len(str(new_seq)) if WHOLE_SEQ == 1 else READ_LEN\n","                NUMBER_OF_READS=(int)(len(str(new_seq))/READ_LEN)\n","                for i in range(NUMBER_OF_READS):\n","                    type_seqs[key].append(str(new_seq)[i*READ_LEN:(i+1)*READ_LEN])\n","            else:\n","                NUMBER_OF_READS=(int)(len(str(new_seq)) - READ_LEN + 1)\n","                for i in range(int(NUMBER_OF_READS/JUMP)):\n","                    type_seqs[key].append(str(new_seq)[i*JUMP:i*JUMP+READ_LEN])\n","    kmer = k\n","    type_texts = {}\n","    for key in newnames.keys():\n","        type_texts[key] = []\n","        for i in type_seqs[key]:\n","            type_texts[key].append(' '.join(getKmers(i, kmer)))\n","\n","    print('k-mers are built.') \n","    merge_texts = []\n","    labels = []\n","    count = 0\n","    for key in newnames.keys(): \n","        for row in type_texts[key]:\n","            merge_texts.append(row)\n","            labels.append(count)\n","        count+=1\n","    labels = np.array(labels)\n","\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(merge_texts)\n","\n","    \n","\n","    encoded_docs = tokenizer.texts_to_sequences(merge_texts)\n","    max_length = max([len(s.split()) for s in merge_texts])\n","    # saving the tokenizer\n","\n","    TOKENIZERPATH = '/content/drive/MyDrive/ML 472/Data/Models/tokenizer_k'+str(k)+'_readWhole.pickle'#+str(READ_LEN)+'.pickle'\n","    with open(TOKENIZERPATH, 'wb') as handle:\n","        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","        pickle.dump(max_length, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","    print('Max_length: ',max_length)    \n","    X = pad_sequences(encoded_docs, maxlen = max_length, padding = 'post')\n","    data_dict = {}\n","\n","    data_dict['X_train'],data_dict['X_test'],data_dict['y_train'],data_dict['y_test'] = train_test_split(X,labels,\n","                                                        test_size=0.20,random_state=42)\n","    #data_dict['y_train']=to_categorical(data_dict['y_train'],25)\n","    #data_dict['y_test']=to_categorical(data_dict['y_test'],25)\n","\n","    vocab_size = len(tokenizer.word_index) + 1\n","    print('Final Vocabulary size is: ', vocab_size)\n","\n","    # Saving the training set and validation set into pickle file.\n","    f =open(OUTPUTFILEPATH, 'wb')\n","    pickle.dump(data_dict, f)\n","    pickle.dump(vocab_size, f)\n","    f.close()\n","    print('X_train, X_test, y_train, y_test, vocab saved in: ',OUTPUTFILEPATH )\n","\n","# You neeed to specify where you want to save your Output dictionary file, in your drive.\n","OUTPUTFILEPATH = '/content/drive/MyDrive/ML 472/Data/Final_data_dicts/Final_data_dict_k15_readWhole.pickle'\n","    \n","#Function 'prepare_training_dataset' takes 5 arguments: k, MOVE_WINDOW, READ_LEN, JUMP, WHOLE_SEQ, and OUTPUTFILENAME\n","prepare_training_dataset(15,0,0,400,1,OUTPUTFILEPATH)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["k-mers are built.\n","Max_length:  14811\n","Final Vocabulary size is:  3901291\n","X_train, X_test, y_train, y_test, vocab saved in:  /content/drive/MyDrive/ML 472/Data/Final_data_dicts/Final_data_dict_k15_readWhole.pickle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBjZxqcVE4ja","executionInfo":{"status":"ok","timestamp":1608525589046,"user_tz":-360,"elapsed":19880,"user":{"displayName":"L Lawlight","photoUrl":"","userId":"13905760247926160423"}},"outputId":"6b6706dd-b0a5-492c-f35a-ece0017c9d80"},"source":["import pickle\n","from google.colab import drive\n","drive.mount('/content/drive')\n","OUTPUTFILEPATH = '/content/drive/MyDrive/Final_data_dict_k15_readWhole.pickle'\n","# This chunk of code loads the data from the saved dicitonary. \n","f=open(OUTPUTFILEPATH, 'rb')\n","data_dict=pickle.load(f)\n","vocab_sizeA=pickle.load(f)\n","f.close()\n","\n","X_train = data_dict['X_train'] \n","y_train = data_dict['y_train']\n","X_test = data_dict['X_test']\n","y_test = data_dict['y_test']\n","\n","print('X_train.shape: ', X_train.shape,'\\nX_test.shape: ',X_test.shape, '\\ny_train.shape: ',y_train.shape,'\\ny_test.shape: ',y_test.shape)\n","print('Vocabulary size: ', vocab_sizeA)\n","vocab_size = vocab_sizeA\n","\n","data_dict = {}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","X_train.shape:  (9171, 14811) \n","X_test.shape:  (2293, 14811) \n","y_train.shape:  (9171,) \n","y_test.shape:  (2293,)\n","Vocabulary size:  3901291\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LDzIsNt2vOC3"},"source":["import numpy as np\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.utils.class_weight import compute_sample_weight\n","import warnings\n","warnings.filterwarnings('ignore')\n","from keras.models import load_model\n","from numpy.testing import assert_allclose\n","import matplotlib.pyplot as plt\n","\n","# Cecking if GPU is available\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","# YOU SHOULD CHANGE THIS PATH WHILE YOU ARE RUNNING FOR DIFFERENT K, READ_LENGTH, etc.\n","MODELWEIGHTSPATH = \"/content/drive/MyDrive/weights.best.hdf5\"\n","#----------------------------------------MODEL------------------------------------------------------------------------\n","Vector_dim=24\n","model = Sequential()\n","model.add(Embedding(vocab_size, Vector_dim, input_length=X_train.shape[1])) #dropout = 0.2 #input_length = max_length\n","\n","model.add(Bidirectional(CuDNNLSTM(40)))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(30,activation='relu'))\n","model.add(Dense(25,activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","checkpoint = ModelCheckpoint(MODELWEIGHTSPATH, monitor = 'val_accuracy', verbose = 1, \n","                             save_best_only = True, mode = 'max')\n","print(model.summary())\n","#--------------------------------------------------------------------------------------------------------------------\n","\n","# Set Epochs and Batch size before running\n","epochs = 15\n","batch_size = 64\n","y_train = to_categorical(y_train,25)\n","y_test = to_categorical(y_test,25)\n","\n","\n","history = model.fit(X_train, y_train, epochs=epochs, \n","                    batch_size=batch_size,validation_data=(X_test,y_test),\n","                    shuffle=True,callbacks=[checkpoint])\n","\n","def increaseEpochs(MODELWEIGHTSPATH, epochs, batch_size):\n","    modelpath = MODELWEIGHTSPATH\n","    new_model = load_model(modelpath)\n","    #assert_allclose(model.predict(X_train),new_model.predict(X_train),1e-5)\n","\n","    checkpoint2 = ModelCheckpoint(modelpath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","    callbacks_list = [checkpoint2]\n","    history2 = new_model.fit(X_train, y_train, epochs=epochs,validation_data=(X_test,y_test),callbacks=[checkpoint2])\n","    return new_model, history2\n","\n","def saveModel(model, MODELPATH):\n","    model_json = model.to_json()\n","    with open(\"/content/drive/MyDrive/model.json\", \"w\") as json_file:\n","        json_file.write(model_json)\n","    \n","    print(\"Saved model to: \", MODELPATH)\n","    model.save(MODELPATH)\n","\n","def plotter(history):\n","    plt.figure(figsize=(20,15))\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model Loss', fontsize = 20)\n","    plt.ylabel('Loss', fontsize = 20)\n","    plt.xlabel('Epoch', fontsize = 20)\n","    plt.legend(['Train', 'Validation'], fontsize = 20)\n","    plt.show()\n","\n","    plt.figure(figsize=(20,15))\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_acc'])\n","    plt.title('Model Accuracy', fontsize = 20)\n","    plt.ylabel('Accuracy', fontsize = 20)\n","    plt.xlabel('Epoch', fontsize = 20)\n","    plt.legend(['Train', 'Validation'], fontsize = 20)\n","    plt.show()\n","\n","# IF YOU NEED TO INCREASE EPOCHS TO GET BETTER PERFORMANCE, UNCOMMENT THE FOLLOWING LINE and COPY ALL THE FOLLOWING LINES TO A NEW CELL.  \n","# model = increaseEpochs(MODELWEIGHTSPATH, 30, 64)\n","\n","# CHANGE THE FOLLOWING LINK BEFORE RUNNING FOR DIFFERENT K, READ_LENGTHS.\n","MODELPATH = \"/content/drive/MyDrive/kmer_model_k15_readWhole.h5\"\n","saveModel(model,MODELPATH)\n","\n","#PLOTTING\n","plotter(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TZUSrDQekmde","executionInfo":{"status":"ok","timestamp":1608557092243,"user_tz":-360,"elapsed":1394,"user":{"displayName":"Nishat Anjum","photoUrl":"","userId":"06823098873876595214"}},"outputId":"3bdf908c-fbba-4586-862e-8bcba59dff5c"},"source":["from keras.models import load_model\r\n","from numpy.testing import assert_allclose\r\n","def saveModelFromWeights():  \r\n","    MODELWEIGHTSPATH = \"/content/drive/MyDrive/ML 472/Data/Models/weights.best_k1_readWhole.hdf5\"\r\n","    new_model = load_model(MODELWEIGHTSPATH)\r\n","    model_json = new_model.to_json()\r\n","    with open(\"/content/drive/MyDrive/ML 472/Data/Models/model_k1_readWhole.json\", \"w\") as json_file:\r\n","        json_file.write(model_json)\r\n","    MODELPATH = \"/content/drive/MyDrive/ML 472/Data/Models/kmer_model_k1_readWhole.h5\"\r\n","    print(\"Saved model to: \", MODELPATH)\r\n","    new_model.save(MODELPATH)\r\n","saveModelFromWeights()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Saved model to:  /content/drive/MyDrive/ML 472/Data/Models/kmer_model_k1_readWhole.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"As9kVtNogQRy","colab":{"base_uri":"https://localhost:8080/","height":177},"executionInfo":{"status":"ok","timestamp":1608536183647,"user_tz":-360,"elapsed":88398,"user":{"displayName":"L Lawlight","photoUrl":"","userId":"13905760247926160423"}},"outputId":"0e1616fd-9eba-44c9-a8df-b8f3c681e5cb"},"source":["from keras.models import load_model\r\n","from numpy.testing import assert_allclose\r\n","import pickle\r\n","import numpy as np\r\n","import warnings\r\n","warnings.filterwarnings('ignore')\r\n","\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","def getKmers(sequence, size):\r\n","    return [sequence[x:x+size].upper() for x in range(len(sequence) - size + 1)]\r\n","def process_seq(seq,k,MOVE_WINDOW,READ_LEN,JUMP):\r\n","    chars = set(seq)\r\n","    nucleotide_list = ['A','C','G','T']\r\n","    type_seqs = []\r\n","    for c in chars:\r\n","        if c not in nucleotide_list:\r\n","            seq = seq.replace(c,'')\r\n","    if MOVE_WINDOW == 0:\r\n","        if READ_LEN==0:\r\n","            READ_LEN = len(seq)\r\n","        NUMBER_OF_READS=(int)(len(seq)/READ_LEN)\r\n","        for i in range(NUMBER_OF_READS):\r\n","            type_seqs.append(seq[i*READ_LEN:(i+1)*READ_LEN])\r\n","    else:\r\n","        NUMBER_OF_READS=(int)(len(seq) - READ_LEN + 1)\r\n","        for i in range(int(NUMBER_OF_READS/JUMP)):\r\n","            type_seqs.append(seq[i*JUMP:i*JUMP+READ_LEN])\r\n","    kmer = k\r\n","    type_texts = []\r\n","    for i in type_seqs:\r\n","        type_texts.append(' '.join(getKmers(i, kmer)))\r\n","    return type_texts\r\n","\r\n","def predict(seq):\r\n","    newnames={'B': 5727, 'C': 2077, '01_AE': 1426, 'A1': 498, '01B': 210, \r\n","                    '02_AG': 168, 'BF1': 143, 'A6': 117, 'A1C': 111, 'G': 96, 'BC': 95, \r\n","                    'A1D': 94, 'AD': 94, 'D': 87, 'F1': 82, 'A1CD': 62, 'CD': 61, 'O': 57,\r\n","                    '0107': 57, '01BC': 50, '07_BC': 41, '08_BC': 35, '02A1': 29, \r\n","                    '11_cpx': 25, '35_AD': 22}\r\n","    types = list(newnames.keys())\r\n","    \r\n","    k = [1,21,15]\r\n","    MOVE_WINDOW = [1,0,0]\r\n","    READ_LEN = [7500,0,1000]\r\n","    JUMP=[400,400]\r\n","    NUM_MODELS = len(k)\r\n","    saved_models = {\r\n","            '117500':'/content/drive/MyDrive/ML 472/Data/Models/kmer_model_k_1_sliding.h5',\r\n","            '2100':'/content/drive/MyDrive/ML 472/Data/Models/kmer_model_k21_readWhole.h5',\r\n","            '1501000':'/content/drive/MyDrive/ML 472/Data/Models/kmer_model_k15_read1000.h5'\r\n","    }\r\n","    saved_tokenizers = {\r\n","            '117500':'/content/drive/MyDrive/ML 472/Data/Models/tokenizer.pickle',\r\n","            '2100':'/content/drive/MyDrive/ML 472/Data/Models/tokenizer_k21_readWhole.pickle',\r\n","            '1501000':'/content/drive/MyDrive/ML 472/Data/Models/tokenizer_k15_read1000.pickle'\r\n","    }\r\n","    predictions = []\r\n","    for i in range(NUM_MODELS):\r\n","        s = str(k[i])+str(MOVE_WINDOW[i])+str(READ_LEN[i])\r\n","        \r\n","        #Loading the saved model\r\n","        MODEL_PATH = saved_models[s]\r\n","        \r\n","        #Loading saved tokenizer \r\n","        TOKENIZERPATH = saved_tokenizers[s]\r\n","        \r\n","        # Preprocessing the newly provided seq\r\n","        type_texts = process_seq(seq,k[i],MOVE_WINDOW[i],READ_LEN[i],JUMP[i])\r\n","        \r\n","        with open(TOKENIZERPATH, 'rb') as handle:\r\n","            tokenizer = pickle.load(handle)\r\n","            max_length = pickle.load(handle)\r\n","        tokenizer.fit_on_texts(type_texts)\r\n","        encoded_docs = tokenizer.texts_to_sequences(type_texts)\r\n","        max_length = max([len(s.split()) for s in type_texts])\r\n","        X = pad_sequences(encoded_docs, maxlen = max_length, padding = 'post')\r\n","        print(X.shape)\r\n","        loaded_model = load_model(MODEL_PATH)\r\n","        y_pred = np.array(loaded_model.predict_classes(X))\r\n","        counts = np.bincount(y_pred)\r\n","        subtype_ = np.argmax(counts)\r\n","        print('k:',k[i],'MOVE_WINDOW:',MOVE_WINDOW[i],'READ_LENGTH:',READ_LEN[i],'\\nPred_class:',types[subtype_])\r\n","        predictions.append(types[subtype_])\r\n","    #print(predictions)\r\n","    return predictions[0]\r\n","#seq_B = 'GGTCTCTCGTTAGACCAGATTTGAGCCTGGAGCTCTCTGGCTAACTAGGGAACCCACTGCTTAAGCCTCAATAAAGCTTGCCTTGAGTGCTTCAAGTAGTGTGTGCCCGTCTGTTGTGTGACTCTGGTAACTAGAGATCCCTCAGACCCTTTTAGTCAGTGTGGAAAATCTCTAGCAGTGGCGCCCGAACAGGGACTTGAAAGCGAAAGGGAAACCAGAGGAGCTCTCTCGACGCAGGACTCGGCTTGCTGAAGCGCGCACGGCAAGAGGCGAGGGGAGGCGACTGGTGAGTACGCCAAAAATTTTGACTAGCGGAGGCTAGAAGGAGAGAGATGGGTGCGAGAGCGTCAGTATTAAGCGGGGGAGAATTAGATCGATGGGAAAAAATTCGGTTAAGGCCAGGGGGAAAGAAAAAATATAAATTAAAACATATAGTATGGGCAAGCAGGGAGCTAGAACGATTCGCAGTTAATCCTGGCCTGTTAGAAACATCAGAAGGCTGTAGACAAATACTGGGACAGCTACAACCATCCCTTCAGACAGGATCAGAAGAACTTAGATCATTATATAATACAGTAGCAACCCTCTATTGTGTGCATCAAAGGATAGAGATAAAAGACACCAAGGAAGCTTTAGACAAGATAGAGGAAGAGCAAAACAAAAGTAAGAAAAAAGCACAGCAAGCAGCAGCTGACACAGGACACAGCAGCCAGGTCAGCCAAAATTACCCTATAGTGCAGAACATCCAGGGGCAAATGGTACATCAGGCCATATCACCTAGAACTTTAAATGCATGGGTAAAAGTAGTAGAAGAGAAGGCTTTCAGCCCAGAAGTGATACCCATGTTTTCAGCATTATCAGAAGGAGCCACCCCACAAGATTTAAACACCATGCTAAACACAGTGGGGGGACATCAAGCAGCCATGCAAATGTTAAAAGAGACCATCAATGAGGAAGCTGCAGAATGGGATAGAGTGCATCCAGTGCATGCAGGGCCTATTGCACCAGGCCAGATGAGAGAACCAAGGGGAAGTGACATAGCAGGAACTACTAGTACCCTTCAGGAACAAATAGGATGGATGACAAATAATCCACCTATCCCAGTAGGAGAAATTTATAAAAGATGGATAATCCTGGGATTAAATAAAATAGTAAGAATGTATAGCCCTACCAGCATTCTGGACATAAGACAAGGACCAAAAGAACCCTTTAGAGACTATGTAGACCGGTTCTATAAAACTCTAAGAGCCGAGCAAGCTTCACAGGAGGTAAAAAATTGGATGACAGAAACCTTGTTGGTCCAAAATGCGAACCCAGATTGTAAGACTATTTTAAAAGCATTGGGACCAGCAGCTACACTAGAAGAAATGATGACAGCATGTCAGGGAGTGGGAGGACCCGGCCATAAGGCAAGAGTTTTGGCTGAAGCAATGAGCCAAGTAACAAATTCAGCTACCATAATGATGCAAAGAGGCAATTTTAGGAACCAAAGAAAGATTGTTAAGTGTTTCAATTGTGGCAAAGAAGGGCACATAGCCAGAAATTGCAGGGCCCCTAGGAAAAAGGGCTGTTGGAAATGTGGAAAGGAAGGACACCAAATGAAAGATTGTACTGAGAGACAGGCTAATTTTTTAGGGAAGATCTGGCCTTCCTACAAGGGAAGGCCAGGGAATTTTCTTCAGAGCAGACCAGAGCCAACAGCCCCACCAGAAGAGAGCTTCAGGTCTGGGGTAGAGACAACAACTCCCTCTCAGAAGCAGGAGCCGATAGACAAGGAACTGTATCCTTTAACTTCCCTCAGATCACTCTTTGGCAACGACCCCTCGTCACAATAAAGATAGGGGGGCAACTAAAGGAAGCTCTATTAGATACAGGAGCAGATGATACAGTATTAGAAGAAATGAGTTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAATTGGAGGTTTTATCAAAGTAAGACAGTATGATCAGATACTCATAGAAATCTGTGGACATAAAGCTATAGGTACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGATTGGTTGCACTTTAAATTTTCCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAAGTTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAGTAGAAATTTGTACAGAAATGGAAAAGGAAGGGAAAATTTCAAAAATTGGGCCTGAAAATCCATACAATACTCCAGTATTTGCCATAAAGAAAAAAGACAGTACTAAATGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCTGGGAAGTTCAATTAGGAATACCACATCCCGCAGGGTTAAAAAAGAAAAAATCAGTAACAGTACTGGATGTGGGTGATGCATATTTTTCAGTTCCCTTAGATGAAGACTTCAGGAAGTATACTGCATTTACCATACCTAGTATAAACAATGAGACACCAGGGATTAGATATCAGTACAATGTGCTTCCACAGGGATGGAAAGGATCACCAGCAATATTCCAAAGTAGCATGACAAAAATCTTAGAGCCTTTTAGAAAACAAAATCCAGACATAGTTATCTATCAATACATGGATGATTTGTATGTAGGATCTGACTTAGAAATAGGGCAGCATAGAACAAAAATAGAGGAGCTGAGACAACATCTGTTGAGGTGGGGACTTACCACACCAGACAAAAAACATCAGAAAGAACCTCCATTCCTTTGGATGGGTTATGAACTCCATCCTGATAAATGGACAGTACAGCCTATAGTGCTGCCAGAAAAAGACAGCTGGACTGTCAATGACATACAGAAGTTAGTGGGAAAATTGAATTGGGCAAGTCAGATTTACCCAGGGATTAAAGTAAGGCAATTATGTAAACTCCTTAGAGGAACCAAAGCACTAACAGAAGTAATACCACTAACAGAAGAAGCAGAGCTAGAACTGGCAGAAAACAGAGAGATTCTAAAAGAACCAGTACATGGAGTGTATTATGACCCATCAAAAGACTTAATAGCAGAAATACAGAAGCAGGGGCAAGGCCAATGGACATATCAAATTTATCAAGAGCCATTTAAAAATCTGAAAACAGGAAAATATGCAAGAACGAGGGGTGCCCACACTAATGATGTAAAACAATTAACAGAGGCAGTGCAAAAAATAACCACAGAAAGCATAGTAATATGGGGAAAGACTCCTAAATTTAAACTACCCATACAAAAGGAAACATGGGAAACATGGTGGACAGAGTATTGGCAAGCCACCTGGATTCCTGAGTGGGAGTTTGTCAATACCCCTCCTTTAGTGAAATTATGGTACCAGTTAGAGAAAGAACCCATAGTAGGAGCAGAAACGTTCTATGTAGATGGGGCAGCTAGCAGGGAGACTAAATTAGGAAAAGCAGGATATGTTACTAATAGAGGAAGACAAAAAGTTGTCACCCTAACTGACACAACAAATCAGAAGACTGAGTTACAAGCAATTCATCTAGCTTTGCAGGATTCGGGATTAGAAGTAAATATAGTAACAGACTCACAATATGCATTAGGAATCATTCAAGCACAACCAGATAAAAGTGAATCAGAGTTAGTCAATCAAATAATAGAGCAGTTAATAAAAAAGGAAAAGGTCTATCTGGCATGGGTACCAGCACACAAAGGAATTGGAGGAAATGAACAAGTAGATAAATTAGTCAGTGCTGGAATCAGGAAAGTACTATTTTTAGATGGAATAGATAAGGCCCAAGATGAACATGAGAAATATCACAGTAATTGGAGAGCAATGGCTAGTGATTTTAACCTGCCACCTGTAGTAGCAAAAGAAATAGTAGCCAGCTGTGATAAATGTCAGCTAAAAGGAGAAGCCATGCATGGACAAGTAGACTGTAGTCCAGGAATATGGCAACTAGATTGTACACATTTAGAAGGAAAAGTTATCCTGGTAGCAGTTCATGTAGCCAGTGGATATATAGAAGCAGAAGTTATTCCAGCAGAAACAGGGCAGGAAACAGCATACTTTCTTTTAAAATTAGCAGGAAGATGGCCAGTAAAAACAATACATACAGACAATGGCAGCAATTTCACCAGTACTACGGTTAAGGCCGCCTGTTGGTGGGCGGGAATCAAGCAGGAATTTGGAATTCCCTACAATCCCCAAAGTCAAGGAGTAGTAGAATCTATGAATAAAGAATTAAAGAAAATTATAGGCCAGGTAAGAGATCAGGCTGAACATCTTAAGACAGCAGTACAAATGGCAGTATTCATCCACAATTTTAAAAGAAAAGGGGGGATTGGGGGGTACAGTGCAGGGGAAAGAATAGTAGACATAATAGCAACAGACATACAAACTAAAGAATTACAAAAACAAATTACAAAAATTCAAAATTTTCGGGTTTATTACAGGGACAGCAGAGATCCACTTTGGAAAGGACCAGCAAAGCTCCTCTGGAAAGGTGAAGGGGCAGTAGTAATACAAGATAATAGTGACATAAAAGTAGTGCCAAGAAGAAAAGCAAAGATCATTAGGGATTATGGAAAACAGATGGCAGGTGATGATTGTGTGGCAAGTAGACAGGATGAGGATTAGAACATGGAAAAGTTTAGTAAAACACCATATGTATGTTTCAGGGAAAGCTAGGGGATGGTTTTATAGACATCACTATGAAAGCCCTCATCCAAGAATAAGTTCAGAAGTACACATCCCACTAGGGGATGCTAGATTGGTAATAACAACATATTGGGGTCTGCATACAGGAGAAAGAGACTGGCATCTGGGTCAGGGAGTCTCCATAGAATGGAGGAAAAAGAGATATAGCACACAAGTAGACCCTGAACTAGCAGACCAACTAATTCATCTGTATTACTTTGACTGTTTTTCAGACTCTGCTATAAGAAAGGCCTTATTAGGACATATAGTTAGCCCTAGGTGTGAATATCAAGCAGGACATAACAAGGTAGGATCTCTACAATACTTGGCACTAGCAGCATTAATAACACCAAAAAAGATAAAGCCACCTTTGCCTAGTGTTACGAAACTGACAGAGGATAGATGGAACAAGCCCCAGAAGACCAAGGGCCACAGAGGGAGCCACACAATGAATGGACACTAGAGCTTTTAGAGGAGCTTAAGAATGAAGCTGTTAGACATTTTCCTAGGATTTGGCTCCATGGCTTAGGGCAACATATCTATGAAACTTATGGGGATACTTGGGCAGGAGTGGAAGCCATAATAAGAATTCTGCAACAACTGCTGTTTATCCATTTCAGAATTGGGTGTCGACATAGCAGAATAGGCGTTACTCAACAGAGGAGAGCAAGAAATGGAGCCAGTAGATCCTAGACTAGAGCCCTGGAAGCATCCAGGAAGTCAGCCTAAAACTGCTTGTACCACTTGCTATTGTAAAAAGTGTTGCTTTCATTGCCAAGTTTGTTTCACAACAAAAGCCTTAGGCATCTCCTATGGCAGAAGAAGCGGAGACAGCGACGAAACCTCCTCAAGGCAGTCAGACTCATCAAGTTTCTCTATCAAAGCAGTAAGTAGTACATGTAATGCAACCTATACAAATAGCAATAGCAGCATTAGTAGTAGCAATAATAATAGCAATAGTTGTGTGGTCCATAGTAATCATAGAATATAGGAAAATATTAAGACAAAGAAAAATAGACAGGTTAATTGATAGACTAATAGAAAGAGCAGAAGACAGTGGCAATGAGAGTGAAGGAGAAATATCAGCACTTGTGGAGATGGGGGTGGAAATGGGGCACCATGCTCCTTGGGATATTGATGATCTGTAGTGCTACAGAAAAATTGTGGGTCACAGTCTATTATGGGGTACCTGTGTGGAAGGAAGCAACCACCACTCTATTTTGTGCATCAGATGCTAAAGCATATGATACAGAGGTACATAATGTTTGGGCCACACATGCCTGTGTACCCACAGACCCCAACCCACAAGAAGTAGTATTGGTAAATGTGACAGAAAATTTTAACATGTGGAAAAATGACATGGTAGAACAGATGCATGAGGATATAATCAGTTTATGGGATCAAAGCCTAAAGCCATGTGTAAAATTAACCCCACTCTGTGTTAGTTTAAAGTGCACTGATTTGGGGAATGCTACTAATACCAATAGTAGTAATACCAATAGTAGTAGCGGGGAAATGATGATGGAGAAAGGAGAGATAAAAAACTGCTCTTTCAATATCAGCACAAGCATAAGAGGTAAGGTGCAGAAAGAATATGCATTTTTTTATAAACTTGATATAATACCAATAGATAATGATACTACCAGCTATACGTTGACAAGTTGTAACACCTCAGTCATTACACAGGCCTGTCCAAAGGTATCCTTTGAGCCAATTCCCATACATTATTGTGCCCCGGCTGGTTTTGCGATTCTAAAATGTAATAATAAGACGTTCAATGGAACAGGACCATGTACAAATGTCAGCACAGTACAATGTACACATGGAATTAGGCCAGTAGTATCAACTCAACTGCTGTTGAATGGCAGTCTAGCAGAAGAAGAGGTAGTAATTAGATCTGCCAATTTCACAGACAATGCTAAAACCATAATAGTACAGCTGAACCAATCTGTAGAAATTAATTGTACAAGACCCAACAACAATACAAGAAAAAGTATCCGTATCCAGAGGGGACCAGGGAGAGCATTTGTTACAATAGGAAAAATAGGAAATATGAGACAAGCACATTGTAACATTAGTAGAGCAAAATGGAATGCCACTTTAAAACAGATAGCTAGCAAATTAAGAGAACAATTTGGAAATAATAAAACAATAATCTTTAAGCAATCCTCAGGAGGGGACCCAGAAATTGTAACGCACAGTTTTAATTGTGGAGGGGAATTTTTCTACTGTAATTCAACACAACTGTTTAATAGTACTTGGTTTAATAGTACTTGGAGTACTGAAGGGTCAAATAACACTGAAGGAAGTGACACAATCACACTCCCATGCAGAATAAAACAATTTATAAACATGTGGCAGGAAGTAGGAAAAGCAATGTATGCCCCTCCCATCAGCGGACAAATTAGATGTTCATCAAATATTACAGGGCTGCTATTAACAAGAGATGGTGGTAATAACAACAATGGGTCCGAGATCTTCAGACCTGGAGGAGGAGATATGAGGGACAATTGGAGAAGTGAATTATATAAATATAAAGTAGTAAAAATTGAACCATTAGGAGTAGCACCCACCAAGGCAAAGAGAAGAGTGGTGCAGAGAGAAAAAAGAGCAGTGGGAATAGGAGCTTTGTTCCTTGGGTTCTTGGGAGCAGCAGGAAGCACTATGGGCGCACGGTCAATGACGCTGACGGTACAGGCCAGACAATTATTGTCTGGTATAGTGCAGCAGCAGAACAATTTGCTGAGGGCTATTGAGGCGCAACAGCATCTGTTGCAACTCACAGTCTGGGGCATCAAGCAGCTCCAGGCAAGAATCCTGGCTGTGGAAAGATACCTAAAGGATCAACAGCTCCTGGGGATTTGGGGTTGCTCTGGAAAACTCATTTGCACCACTGCTGTGCCTTGGAATGCTAGTTGGAGTAATAAATCTCTGGAACAGATTTGGAATAACATGACCTGGATGGAGTGGGACAGAGAAATTAACAATTACACAAGCTTAATACATTCCTTAATTGAAGAATCGCAAAACCAGCAAGAAAAGAATGAACAAGAATTATTGGAATTAGATAAATGGGCAAGTTTGTGGAATTGGTTTAACATAACAAATTGGCTGTGGTATATAAAAATATTCATAATGATAGTAGGAGGCTTGGTAGGTTTAAGAATAGTTTTTGCTGTACTTTCTATAGTGAATAGAGTTAGGCAGGGATATTCACCATTATCGTTTCAGACCCACCTCCCAACCCCGAGGGGACCCGACAGGCCCGAAGGAATAGAAGAAGAAGGTGGAGAGAGAGACAGAGACAGATCCATTCGATTAGTGAACGGATCCTTAGCACTTATCTGGGACGATCTGCGGAGCCTGTGCCTCTTCAGCTACCACCGCTTGAGAGACTTACTCTTGATTGTAACGAGGATTGTGGAACTTCTGGGACGCAGGGGGTGGGAAGCCCTCAAATATTGGTGGAATCTCCTACAGTATTGGAGTCAGGAACTAAAGAATAGTGCTGTTAGCTTGCTCAATGCCACAGCCATAGCAGTAGCTGAGGGGACAGATAGGGTTATAGAAGTAGTACAAGGAGCTTGTAGAGCTATTCGCCACATACCTAGAAGAATAAGACAGGGCTTGGAAAGGATTTTGCTATAAGATGGGTGGCAAGTGGTCAAAAAGTAGTGTGGTTGGATGGCCTACTGTAAGGGAAAGAATGAGACGAGCTGAGCCAGCAGCAGATGGGGTGGGAGCAGCATCTCGAGACCTGGAAAAACATGGAGCAATCACAAGTAGCAATACAGCAGCTACCAATGCTGCTTGTGCCTGGCTAGAAGCACAAGAGGAGGAGGAGGTGGGTTTTCCAGTCACACCTCAGGTACCTTTAAGACCAATGACTTACAAGGCAGCTGTAGATCTTAGCCACTTTTTAAAAGAAAAGGGGGGACTGGAAGGGCTAATTCACTCCCAACGAAGACAAGATATCCTTGATCTGTGGATCTACCACACACAAGGCTACTTCCCTGATTGGCAGAACTACACACCAGGGCCAGGGGTCAGATATCCACTGACCTTTGGATGGTGCTACAAGCTAGTACCAGTTGAGCCAGATAAGGTAGAAGAGGCCAATAAAGGAGAGAACACCAGCTTGTTACACCCTGTGAGCCTGCATGGAATGGATGACCCTGAGAGAGAAGTGTTAGAGTGGAGGTTTGACAGCCGCCTAGCATTTCATCACGTGGCCCGAGAGCTGCATCCGGAGTACTTCAAGAACTGCTGACATCGAGCTTGCTACAAGGGACTTTCCGCTGGGGACTTTCCAGGGAGGCGTGGCCTGGGGGACTGGGGAGTGGCGAGCCCTCAGATGCTGCATATAAGCAGCTGCTTTTTGCCTGTACTGGGTCTCTCTGGTTAGACCAGATTTGAGCCTGGGAGCTCTCTGGCTAACTAGGGAACCCACTGCTTAAGCCTCAATAAAGCTTGCCTTGAGTGCTTCA'\r\n","#seq_C='TGGAAGGGTTAATTTACTCCAAGAAAAGGCAAGAAATCCTTGATTTGTGGGTCTATCACACACAAGGCTTCTTCCCTGATTGGCAAAACTACACACCGGGACCAGGAGTCAGATACCCACTGACTTTTGGGTGGTGCTTCAAGCTGGTACCAGTTGACCCAAGGGAAGTAGAAGAGGCCAACGAAGGAGAAGACAACTGTTTGCTACACCCTGTGTGCCAGCATGGAATGGAGGATGAACACAGAGAAGTATTAAAGTGGAAGTTTGACAGTCAGCTAGCACGCAGACACATGGCCCGCGAGCTACATCCGGAGTTTTACAAAGACTGCTGACACAGAAGGGACTTTCCGCTGGGACTTTCCACTGGGGCGTTCCAGGAGGTGTGGTCTGGGCGGGACTGGGAGTGGTCAACCCTCAGATGCGGCATATAAGCCGCTGCTTTTCGCTTGTACTGGGTCTCTCTAGGTAGACCAGATCTGAGCCTGGGAGCTCTCTGGCTATCTAGGGAACCCACTGCTTAAGCCTCAATAAAGCTTGCCTTGAGTGCTCTGAGCAGTGTGTGCCCGTCTATTGTGTGACTCTGGTAACTAGAGATCCCTCAGACCCTTTTGGTAGTGTGGAAAATCTCTAGCAGTGGCGCCCGAACAGGGACTTGAAAGCGAAAGTAAGACCAGAGAAGATCCTCTAGACGCAGGACTCGGCTTGCTGAAGTGCACTCGGCAAGAGGCGAGAGCGGCGACTGGTGAGTACGCCAATTTTATTTGACTAGCGGAGGCTAGAAGGAGAGAGATGGGTGCGAGAGCGTCAATATTAAGAGGGGGAAAATTAGATAAATGGGAAAGAATTAGGTTAAGGCCAGGGGGAAAGAAACACTATATGCTAAAACACCTAGTATGGGCAAGCAGGGAGCTGGAAAGATTCGCACTCAACCCTGGCCTTTTAGAGACAGCAGAAGGCTGTAAACAAATAATAAAACAGCTACAACCAGCTCTTCAGACAGGAACAGAGGAACTTAAATCATTACACAACACAGTAGCAACTCTCTATTGTGTACATGCAGGGATAGAAGTACGAGACACCAAAGAAGCCTTAGACAAGATAGAGGAAGAACAAAACAAAATTCAGCAAAAAACACAACAGGCAAAAGAGGCTGACGGGAAGGTCAGTCAAAATTATCCTATAGTGCAGAATCTCCAAGGGCAAATGGTACACCAGGCCATATCACCTAGAACTTTGAATGCATGGGTAAAAGTAATAGAGGAGAAGGCTTTTAGCCCAGAGGTAATACCCATGTTTACAGCATTATCAGAAGGAGCCACCCCACAAGACTTAAACACCATGTTAAATACAGTGGGGGGACATCAAGCAGCCATGCAAATGTTAAAAGATACCATCAATGAAGAGGCTGCAGAATGGGATAGATTACATCCAATCCATGCAGGGCCTATTGCACCAGGCCAAATGAGAGAACCAAGGGGAAGTGACATAGCAGGAACTACTAGTAGCCTTCAGGAACAAATAGCATGGATGACAGGTAACCCACCTGTTCCAGTGGGAGACATCTATAAAAGATGGATAATTCTGGGGTTAAATAAAATAGTAAGAATGTATAGCCCTGTTAGCATTTTGGACATAAGACAAGGGCCAAAGGAACCCTTTAGAGACTATGTAGACCGGTTCTTTAAAACTTTAAGAGCTGAACAAGCTACACAAGATGTAAAAAATTGGATGACAGACACCTTGTTGGTCCAAAATGCGAATCCAGATTGTAAGACCATTTTAAGAGCATTAGGACCAGGGGCTTCATTAGAAGAGATGATGACAGCATGTCAGGGAGTGGGAGGACCTGGCCACAAAGCAAGAGTGTTGGCTGAGGCAATGAGCCAAGCAAACAGTACCATACTGATGCAGAGAAGCAATTTTAAAGGCTCTAAAAGAATTGTTAAATGTTTCAACTGTGGCAAGGAGGGGCACATAGCCAAAAATTGCAGGGCCCCTAGGAAAAAAGGCTGTTGGAAATGTGGAAAGGAAGGACACCAAATGAAAGACTGTACTGAGAGGCAGGCTAATTTTTTAGGGAAAATTTGGCCTTCCCACAAGGGGAGGCCAGGGAATTTCCTCCAGAGCAGACCGGAGCCAACAGCCCCACCAGCAGAGAGCTTCAGGTTCGAGGAGACAACCCCAGCTCCAAAGCAGGAGCCGAAAGACAGGGAACCCTTAACTTCCCTCAAATCACTCTTTGGCAGCGACCTCTTGTCTCAATAAGAGTAGGGGGCCAAATAAAAGAGGCTCTCTTAGACACAGGAGCAGATGATACAGTATTAGAAGAAGTAAATTTGCCAGGAAAATGGAAACCAAAAATGATAGGAGGAATTGGAGGTTTTATCAAAGTAAGACAATATGATCAAATACCTATAGAAATTTGTGGAAAAAAGGCTATAGGTACAGTATTAGTGGGACCCACACCTATCAACATAATTGGAAGAAATATGTTGACTCAGCTTGGATGCACACTAAATTTTCCAATCAGTCCCATTGAAACTGTACCAGTAAAATTAAAGCCAGGAATGGATGGCCCAAAGGTTAAACAATGGCCATTGACAGAAGAGAAAATAAAAGCATTAACAGCAATTTGTGATGAAATGGAGAAGGAAGGAAAAATTACAAAAATTGGGCCTGAAAATCCATATAACACTCCAATATTTGCTATAAAAAAGAAGGACAGTATTAAGTGGAGAAAATTAGTAGATTTCAGGGAACTCAATAAAAGAACTCAAGATTTTTGGGAAGTTCAATTAGGAATACCACACCCAGCAGGGTTAAAAAAGAAAAAATCAGTGACAGTACTGGATGTGGGGGATGCATATTTTTCAGTTCCTTTATATGAAGACTTCAGGAAATATACTGCATTCACCATACCTAGTATAAACAATGAAACACCAGGGATTAGGTATCAATATAATGTGCTTCCACAGGGATGGAAAGGATCACCAGCAATATTCCAGAGTAGCATGATAAGAATCTTAGAGCCCTTTAGGGCACAAAATCCAGAAATAGTCATCTATCAATATATGGATGACTTGTATGTAGGATCTGACTTAGAAATAGGGCAACATAGAGCAAAAATAGAGGAGTTAAGAGAACATCTGTTAAAGTGGGGATTTACCACACCAGACAAGAAACATCAGAAGGAACCTCCATTTCTTTGGATGGGGTATGAACTCCATCCTGACAAATGGACAGTACAGCCTATACAGCTGCCAGAAAAGGATAGCTGGACTGTCAATGATATACAGAAGTTAGTGGGAAAATTAAACTGGGCAAGTCAAATTTACCCAGGAATTAAAGTAAGGCAACTTTGTAAACTCCTTAGGGGGGCCAAAGCACTAACAGACATAGTACCACTAACTGAAGAAGCAGAATTAGAATTGGCAGAAAACAGGGAAATTCTAAAAGAACCAGTACATGGAGTATATTATGACCCATCAAAAGACTTGATAGCTGAAATACAGAAACAGGGGCAGGACCAATGGACATATCAAATTTACCAAGAACCATTCAAAAATCTGAAAACAGGGAAGTATGCAAAAAGGAGGACTGCCCACACTAATGATGTAAAACAGTTAACAGAGGCTGTGCAGAAAATAGCCATGGAAAGCATAGTAATATGGGGAAAGACTCCTAAATTTAGATTACCTATCCAAAAAGAAACATGGGAGACATGGTGGACAGACTATTGGCAAGCCACCTGGATTCCTGAGTGGGAATTTGTTAATACCCCTCCCCTAGTAAAATTATGGTACCAGCTGGAGAAAGATCCCATAGCAGGAGTAGAAACTTTCTATGTAGATGGAGCAGCTAATAGGGAAACTAAGTTAGGAAAAGCAGGGTATGTTACTGACAGAGGAAGGCAGAAAATTGTTTCTCTAACTGAAACCACAAATCAGAAGACTGAGTTGCAAGCAATTTATCTAGCTTTGCAAGATTCAGGATCAGAAGTAAACATAGTAACAGATTCACAGTATGCATTAGGGATCATTCAAGCACAACCAGATAAGAGTGAATCAGAGTTAGTTAACCAAATAATCGAACAGTTAATAAAAAAGGAAAGGGTCTATCTGTCATGGGTACCAGCACATAAAGGAATTGGAGGAAATGAACAAGTAGATAAATTAGTAAGTAGTGGAATCAGGAAAGTGCTATTTCTAGATGGAATAGATAAAGCTCAAGAAGAGCATGAAAAGTATCACAGCAATTGGAGAGCAATGGCCAGTGACTTTAATCTACCACCCGTAGTAGCAAAAGAAATAGTAGCTAGCTGTGATCAATGTCAGCTAAAAGGGGAAGCCATGCATGGACAAGTAGACTGTAGTCCAGGGATATGGCAATTAGATTGTACACATTTAGAAGGAAAAATCATCCTGGTAGCAGTCCATGTAGCCAGTGGCTACATAGAAGCAGAGGTTATTCCAGCAGAAACAGGACAAGAAACAGCATACTTTATACTAAAATTAGCAGGAAGATGGCCAGTCAAAGTAATACATACAGACAATGGTAGTAATTTCACCAGTGCTGCAGTCAAGGCAGCCTGTTGGTGGGCAGGTATCCAACAGGAATTTGGGATTCCCTACAATCCCCAAAGTCAGGGAGTAGTAGAATCTATGAATAAAGAATTAAAGAAAATTATAGGGCAGGTAAGAGATCAAGCTGAGCACCTTAAGACAGCAGTACAAATGGCAGTATTCATTCACAATTTTAAAAGAAAAGGGGGGATTGGGGGGTACAGTGCAGGGGAAAGAATAATAGACATAATAGCAACAGACATACAAACTAAAGAATTACAAAAACAAATTATAAAAATTCAAAATTTTCGGGTTTATTACAGAGACAGCAGAGACCCCATTTGGAAAGGACCAGCCAAACTACTCTGGAAAGGTGAAGGGGCAGTAGTAATACAAGATAATAGTGACATAAAGGTAGTACCACGGAGGAAAGCAAAAATCATTAAGGACTATGGAAAACAGATGGCAGGTGCTGATTGTGTGGCAGGTAGACAGGATGAAGATTAGAACATGGAATAGTTTAGTAAAACACCATATGTATGTTTCAAGGAGAGCTAAAGGATGGTTTTACAGACATCATTATGACAGCAGACATCCAAAAGTAAGTTCAGAAGTACACATCCCATTAGGGGAGGCTAGATTAGTAATAAAAACATATTGGGGGTTGCAAACAGGAGAAAGAGACTGGCATTTGGGTCATGGAGTCTCCATAGAATGGAGATTGAGAAGATATAACACACAAATAGAACCTGGCCTGGCAGACCAGCTAATCCATATGCATTATTTTGATTGTTTTGCAGACTCTGCCATAAGGAAAGCCATATTAGGACACATAGTTATTCCTAGGTGTGACTATCAAGCAGGACATAATAAGGTAGGATCTCTACAATACCTGGCACTGACAGCACTGATAAAACCAAAAAAGATAAAGCCACCTCTGCCTAGTATTAAGAAATTAGTAGAGGATAGATGGAACAATCCCCAGAAGATCAGGGGCCGCAGAGGGAACCATACAATGAATGGACACTAGAGCTTCTAGAGGAACTCAAGCAGGAAGCTGTCAGACACTTTCCTAGACCATGGCTTCATGGCTTAGGACAATATGTCTATGAAACATATGGGGATACTTGGACAGGAGTCGAAGCTATAATAAGACTACTGCAACAACTACTGTTTATTCATTTCAGAATTGGGTGCCAGCATAGCAGAATAGGCATTTTGCGACAGAGAAGAGCAAGAAATGGAGCCAGTAGATCCTAACCTAGAGCCCTGGAACCATCCAGGAAGTCAGCCTAAAACTGCTTGCAATCAATGTTATTGTAAACGCTGTAGCTATCATTGTCTAGTTTGCTTTCAGAAAAAAGGCTTAGGCATTTCCTATGGCAGGAAGAAGCGGAGACAGCGACGAAGCGCTCCTCCAAGCAGTGAGGATCATCAAAATCTTATATCAAAGCAGTAAGTATCTGTAATGATAGATTTAGATTATAGGTTAGGAGTAGGAGCATTGATAGTAGCACTAATCATAGCAATAGTTGTGTGGACCATAGTATATATAGAATATAGGAAATTGGTAAGACAAAGCAAAATAAACTGGTTAATTAAAAGAATTAGGGAAAGAGCAGAAGACAGTGGCAATGAGAGTGAGGGGGACACTGAGGAATTATCAACAATGGTGGATATGGGGCGTCTTAGGCTTTTGGATGTTAATGATTTGTAATGGGGGAGGAAACTTGTGGGTCACAGTCTATTATGGGGTACCTGTGTGGAAAGAAGCAAAAACCACTCTACTCTGTGCATCAGATGCCAAAGCATATGAGAGGGAAGTGCATAATGTCTGGGCTACACATGCCTGTGTACCCACAGACCCCAACCCACAAGAAATAGTTTTGGGAAATGTAACAGAAAATTTTAACATGTGGAAAAATGACATGGTGGATCAGATGCATGAGGATGTAATCAGTTTATGGGATCAAAGCCTAAAGCCATGTGTAAAATTGACCCCACTCTGTGTCACTTTAGAATGTAGAAATGTTAGCAGAAATGTTAGCAGTTATAATACCTACAATGGGAGCGTGGAGGAAATAAAAAATTGCTCTTTCAATGCAACCCCAGAAGTAAGAGATAGGAAGCAGAGAATGTATGCTCTCTTTTATGGACTTGATATAGTACCACTTAATAAGAAGAACTCTAGTGAGAACTCCAGTGAGTATAGATTAATAAATTGTAATACCTCAGCCATAACACAAGCCTGTCCAAAGGTCACTTTTGATCCAATTCCTATACACTATTGTGCTCCGGCTGGTTATGCGATTCTAAAGTGTAATAATAAGACATTCAATGGGACAGGACCATGCAATAATGTTAGTACAGTACAATGTACACATGGAATTAAGCCAGTAGTATCAACTCAACTACTGTTAAATGGTAGCCTAGCAGAAGGAGAGATAATAATTAGATCTGAAAATCTGACAAACAATGTCAAAACAATAATAGTACATCTTAATCAATCTGTAGAAATTGTGTGTACAAGACCCAATAATAATACAAGAAAAAGTATAAGGATAGGACCAGGACAAACATTCTATGCAACAGGAGACATAATAGGAGACATAAGACAAGCACATTGTAACATTAGTAGAGATAAATGGAATGAAACTTTACAAAGGGTAGGTAAAAAATTAGCAGAACACTTCCATAATAAGACAATAAAATTTGCATCATCCTCAGGAGGGGACCTAGAAATTACAACACATAGCTTTAATTGTAGAGGAGAATTTTTCTATTGTAATACATCAGGCCTGTTTAATGGTACATACATGCCTACATACATGCCTAATGGTACAGAAAGTAATTCAAACTCAACTATCACAATCCCATGCAGAATAAAGCAAATTATAAACATGTGGCAGGAGGTAGGACGAGCAATGTATGCCCCTCCCATTGCAGGAAACATAACATGTACATCAAATATCACAGGACTACTATTGGTACATGATGGAGGAATAAAGGAAAATGATACAGAGAATAAGACAGAGATATTTAGACCTGGAGGAGGAGATATGAGGGACAATTGGAGAAGTGAATTATATAAATATAAAGTGGTAGAAATTAAGCCATTGGGAGTAGCACCCACTGCAGCAAAAAGGAGAGTGGTGGAGAGAGAAAAAAGAGCAGTGGGAATAGGAGCTGTGTTCCTTGGGTTCTTGGGAGCAGCAGGAAGCACTATGGGCGCGGCGTCAATAACGCTGACGGCACAGGCCAGACAATTGTTGTCTGGTATAGTGCAACAGCAAAGCAATTTGCTGAGGGCTATAGAGGCGCAACAGCATCTGTTGCAACTCACAGTCTGGGGCATTAAGCAGCTCCAGACAAGAGTCCTGGCTATAGAGAGATACCTAAAGGATCAACAGCTCCTAGGGATTTGGGGCTGCTCTGGAAAACTCATCTGCACTACTGCTGTACCTTGGAACTCCAGTTGGAGTAACAAAACTCAAAGTGAGATTTGGAATAACATGACCTGGATGCAGTGGGATAGAGAAGTTAGTAATTACACAAACATAATATACAGCTTGCTTGAAGAATCGCAAAACCAGCAGGAAAAAAATGAAAAAGATTTATTAGCATTGGACAGTTGGAAAAATCTATGGAGTTGGTTTGACATAACAAATTGGCTGTGGTATATAAAAATATTCATAATGATAGTAGGAGGCTTGATAGGTTTAAGAATAATTTTTGCTGTGCTCTCTATAGTGAATAGAGTTAGGCAGGGATACTCACCTTTGTCGTTTCAGACCCTTACCCCGAACCCAAGGGGACCCGACAGGCTCGGAAGAATCGAAGAAGAAGGTGGAGAGCAAGACAAAGACAGATCCATTCGATTAGTGAACGGATTCTTAGCACTTGCCTGGGACGATCTACGGAACCTGTGCCTCTTCAGCTACCACCGATTGAGAGACTTCATATCGGTGGCAGCGAGAGTGGTGGAACTTCTGGGACGCAGCAGTTGGGAAGCCCTTAAATATCTGGGAAGTCTTGTGCAGTATTGGGGTCTGGAGCTAAAAAAGAGTGCTATTAGTCTGTTTGATAGCATAGCAATAGTAGTAGCTGAAGGAACAGATAGGATTATAGAATTAGTACAAGGATTTTGTAGAGCTATCCGCAACATACCTACAAGAATAAGACAGGGCTTTGAAGCAGCTTTGCAATAAAATGGGGGGCAAGTGGTCAAAATGCAGCATAGTAGGATGGCCTGCTATAAGAGAGAGAATGAGACGAGCTGAGCCAGCAGCAGAAGGAGTAGGAGCAGCGTCTCAAGACTTAGATAAACATGGAGCACTTACAAGCAGCAACACAGACACCACTAATGCTGATTGTGCTTGGCTGAGAGCACAGGAGGAGGAAGGAGAAGTAGGCTTTCCAGTCACACCTCAGGTGCCTTTAAGACCAATGACTTATAAGAGCGCATTTGATCTCAGCTTCTTTTTAAAAGAAAAGGGGGGACTGGAAGGGTTAATTTACTCTAAGAAAAGGCAAGAAATCCTTGATTTGTGGGTCTATCACACACAAGGCTTCTTCCCTGATTGGCAAAACTACACACCGGGACCAGGAGTCAGATACCCACTGACTTTTGGGTGGTGCTTCAAGCTGGTACCAGTTGACCCAAGGGAAGTAGAAGAGGCCAACGAAGGAGAAGACAACTGTTTGCTACACCCTGTGTGCCAGCATGGAATGGAGGATGAACACAGAGAAGTATTAAAGTGGAAGTTTGACAGTCAGCTAGCACGCAGACACATGGCCCGCGAGCTACATCCGGAGTTTTACAAAGACTGCTGACACAGAAGGGACTTTCCGCTGGGACTTTCCACTGGGGCGTTCCAGGAGGTGTGGTCTGGGCGGGACTGGGAGTGGTCAACCCTCAGATGCGGCATATAAGCCGCTGCTTTTCGCTTGTACTGGGTCTCTCTAGGTAGACCAGATCTGAGCCTGGGAGCTCTCTGGCTATCTAGGGAACCCACTGCTTAAGCCTCAATAAAGCTTGCCTTGAGTGCTCTGAGCAGTGTGTGCCCGTCTATTGTGTGACTCTGGTAACTAGAGATCCCTCAGACCCTTTTAGTCAGT'\r\n","seq_A1CD='TTCTCTCGACGCAGGACTCGGCTTGCTGAAGCGCGCACGGCAAGAGGCGAGGGGCAGCGAACGGTGAGTACGCAAAAAATTTTTTGACTAGCGGAGGCTAGAAGGAGAGAGATGGGTGCGAGAGCGTCAATATTAAGTGGGGGAAAATTAGATGCATGGGAGAAAATTCGGTTAAGGCCAGGGGGAAAGAAAAAATATAGATTGAAACATCTAGTATGGGCAAGCAGGGAGCTGGACAGATTTGCACTTAACCCTAGCCTTTTAGAAACAACAGAAGGGTGTCAACAAATAATGGACCAGTTACAACCAGCTCTCAAGACAGGAACAGAAGAACTTAGATCATTATATAACACAGTAGCAACCCTCTGGTGCGTACATAAACGGATAGATGTAAAAGACACCAAGGAAGCTCTAGATAAAATAGAGGAAATACAAAAGAAAAGCAAGCAAAAGGCCCAACAGGCAGCAGCTGACACAGGAAATAGCAGCAATGTCAGCCAGAATTACCCTATAGTGCAAAATGCACAAGGGCAAATGGTACACCAGTCCTTGTCACCTAGGACTTTGAATGCATGGGTGAAAGTAATAGAAGAAAAGGCTTTCAGCCCAGAAGTAATACCCATGTTTTCAGCATTATCAGAAGGAGCCACCCCACAAGATTTAAATATGATGCTGAACATAGTAGGGGGACACCAGGCAGCTATGCAAATGTTAAAAGATACCATCAATGAGGAAGCTGCAGAATGGGACAGGATACATCCAGTACATGCAGGGCTTATTGCACCAGGCCAGATGAGAGAACCAAGGGGAAGTGATATAGCAGGAACTACTAGTACCCTTCAGGAACAAATAGCATGGATGACAAGCAATCCACCTATCCCAGTAGGAGACATCTATAAAAGATGGATAATCCTGGGATTAAATAAAATAGTGAGAATGTATAGCCCTGTTAGCATCTTGGATATAAGACAAGGGCCAAAAGAACCCTTCAGAGACTATGTAGATAGGTTCTTTAAAACTCTCAGAGCTGAACAAGCTACACAGGAAGTAAAAAATTGGATGACAGAGACCTTGTTAGTCCAAAATGCGAACCCAGATTGTAAAACTATCTTAAAAGCATTGGGACCAGGGGCTACATTAGAAGAAATGATGACAGCATGTCAGGGAGTGGGGGGACCCGGTCATAAAGCAAGAGTTTTGGCTGAGGCAATGAGCCAAGCAAATGCAAATACTGCTATAATGATGCAGAGAGGCAATTTTAAGGGTCCAAAGAAAATCATTAAGTGTTTCAACTGTGGCAAAGAAGGACACATAGCAAAAAATTGCAGGGCTCCTAGGAAAAAGGGCTGTTGGAAATGTGGAAGGGAAGGACACCAGATGAAAGATTGCACTGAAAGACAGGCTAATTTTTTAGGGAAGATATGGCCTTCCCACAAGGGAAGGCCAGGGAATTTCCTTCAGAGCAGACCAGAACCAACAGCCCCACCAGCAGAGAGCTTCGGGTTTGGAGAAGAGATAACCCCCTCCCAGAAGCAGGAGCAGAAAGACAAGGAACTGTATCCTTTAGCCTCCCTCAAATCACTCTTTGGCAACGACCCCTAGTCAAAGTAAAGATAGGGGGACAGCTAAAAGAAGCTCTATTAGATACAGGAGCAGATGATACAGTATTAGAAGACATAAATTTGCCAGGAAAATGGAAACCAAAAATGATAGGGGGAATTGGAGGCTTTATCAAAGTAAGACAGTATGATCAAATACTCGTAGAAATCTGTGGACATAAAGCTATAGGTACAGTATTAGTAGGACCTACACCTGTCAACATAATTGGAAGAAATTTGTTGACTCAGATTGGTTGCACTTTAAATTTTCCAATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGGATGGATGGCCCAAGAGTTAAACAATGGCCATTGACAGAAGAAAAAATAAAAGCATTAATAGAAATTTGTACAGAGATGGAAAAGGAAGGAAAAATTTCAAGAATTGGGCCTGAAAATCCATACAATACTCCAATATTTGCTATAAAGAAAAAAGACAGTACTAAGTGGAGAAAATTAGTAGATTTCAGAGAACTTAATAAGAGAACTCAAGACTTCTGGGAAGTTCAATTAGGAATACCGCATCCAGCGGGCTTGAAAAAGAAAAAATCAGTAACAATACTAGATGTGGGGGACGCATATTTTTCAGTCCCCTTAGATGAAAGCTTTAGAAAGTATACTGCATTCACCATACCTAGTACAAACAATGAGACACCAGGAATCAGGTATCAGTACAATGTGCTTCCACAGGGATGGAAAGGATCACCGGCAATATTTCAGAGTAGCATGACAAAAATCTTAGAGCCCTTTAGATCAAAAAATCCAGACATGATTATCTATCAATACATGGATGACTTGTATGTAGGATCTGATTTAGAAATAGGACAGCATAGAACAAAAATAGAGGAGTTAAGAGCTCATCTATTGAGCTGGGGATTTACTACACCAGACAAAAAGCATCAGAAAGAACCCCCATTTCTGTGGATGGGATATGAACTCCATCCTGACAAGTGGACAGTCCAATCTATAAAACTGCCAGAAAAAGAAAGCTGGACTGTCAATGATATACAGAAATTAGTGGGGAAATTAAATTGGGCAAGCCAAATTTATCCAGGAATTAAAGTAAAACAGTTGTGTAAACTCCTTAGGGGAGCCAAAGCACTAACAGATGTAGTAACATTGACTGAGGAAGCAGAATTAGAATTGGCAGAGAACAGGGAGATTCTAAAAGACCCTGTGCATGGGGTATATTATGACCCATCAAAGGACTTAATAGCAGAAATACAGAAACAAGGGCAAGAACAATGGACATATCAAATTTATCAAGAGCCATTTAAAAATCTAAAAACAGGGAAGTATGCAAAAAAGAGGTCTGCTCACACTAATGATGTAAAACAATTAGCAGAAGTGGTGCAAAAAGTGGTCATGGAAAGCATAGTAATATGGGGAAAGGCTCCTAAATTTAAATTACCCATACAAAAAGAAACATGGGAAACATGGTGGATGGACTATTGGCAGGCCACCTGGATTCCTGAATGGGAATTTGTCAATACCCCTCCTCTAGTAAAATTATGGTACCAGTTAGAGAAAGACCCCATAATAGGAGCAGAGACTTTCTATGTAGATGGGGCAGCCAATAGGGAAACTAAGCTAGGAAAAGCAGGGTATGTCACTGACAGAGGAAGACAAAAGGTTGTTTCCCTAACTGAGACAACAAATCAAAAGACTGAACTACATGCAATCTATCTAGCCTTGCAGGATTCAGGATCAGAAGTAAACATAGTAACAGACTCACAGTATGCATTAGGAATCATTCAGGCACAACCAGACAGGAGTGAATCAGAGTTAGTCAATCAAATAATAGAGAAGCTAATAGGAAAGGACAAAGTCTACCTGTCATGGGTACCAGCACACAAAGGAATTGGAGGAAATGAACAAGTAGATAAATTAGTCAGTTCTGGAATCAGGAAAGTGCTATTTTTGGATGGGATAGATAAAGCTCAAGAAGAACATGAAAGGTATCACAGCAATTGGAGAGCAATGGCTAGTGACTTTAATCTGCCACCTGTAATAGCAAAAGAAATAGTAGCCAGCTGTGATAAATGTCAGATAAAAGGGGAAGCCATGCATGGACAAGTAGACTGCAGTCCAGGGATATGGCAATTAGATTGCACGCATTTAGAAGGAAAAGTAATTCTGGTAGCAGTCCATGTAGCCAGTGGCTATATAGAAGCAGAAGTTATCCCAGCAGAAACAGGACAGGAGACAGCATACTTTCTACTAAAATTAGCAGGAAGATGGCCAGTAAAAGTAGTACACACAGACAATGGCAGCAATTTCACCAGTGCTGCATTTAAAGCAGCCTGTTGGTGGGCAAGTGTCCAACAGGAATTTGGAATTCCCTACAATCCCCAAAGTCAAGGAGTAGTGGAATCTATGAATAAGGAATTAAAGAAAATCATAGGGCAGGTAAGAGAGCAAGCTGAACACCTTAAGACAGCAGTACAAATGGCAGTATTCATTCACAATTTTAAAAGAAAAGGGGGGATTGGGGGGTACAGTGTAGGGGAAAGAATAATAGACATAATAGCAACAGACATACAAACTAAAGAATTACAAAAACAAATTACAAAAATTCAAAAATTCCGGGTTTATTACAGGGACAGCAGAAATCCAATTTGGAAAGGACCAGCAAAACTACTCTGGAAAGGTGAAGGGGCAGTGGTAATACAGGACAATAGTGATATAAAGGTAGTACCAAGAAGAAAGGCAAAGATCATTAGGGATTATGGAAAACAGATGGCAGGTGATGATTGTGTGGCAGGTAGACAGGATGAGGATTGGAACATGAAATAGTCTAGTAAAACATCATATGTATGTCTCAAAGAAAGCTAGAGGTTGGTTTTATAGACATCACTATSAAACCAGGCATCCAAGAATAAGTTCAGAAGTACACATCCCACTAGGGGATGCTAAAATAGTAGTAAGAACATATTGGGGTCTACACACAGGAGAAAAAGACTGGCACCTGGGTCATGGGGTCTCCATAGAATGGAGGCTAAGAAAGTATAGCACACAAATAGATCCTGACCCGGCAGACCAACTAATTCACCTGCATTATTTTGACTGTTTTTCAGACTCTGCCATAAGGAAAGCCATATTAGGGCAAGTAGTTAGCCCTAGGTGTGACTATACAGCAGGACATAACAAGGTAGGATCTCTACAATATTTAGCACTGAAAGCATTAGTAACACCAACAAGAGTAAAGCCACCTTTGCCTAGTGTTAGGAAATTAGCAGAGGATAGATGGAGCAAGTCCCAAAAGACCAGGGGCCTCAGAGGGAGCCTTACAATGAATGGATGTTAGATCTGCTAGAAGATCTTAAGCATGAAGCTGTCAGACATTTTCCTAGGCCATGGCTTCATGGATTAGGACAACATATCTATAGCACATATGGGGATACTTGGGAAGGAGTTGAAGCTATAATAAGAATTTTGCAGCAACTACTGTTTGTTCATTTCAGAATCGGGTGCCAACACAGCAGAATAGGCATTATTCGAGGGAGGAGAAGAGTCAGGAATGGATCTAGTAGATCCTAACCTAGAGCCCTGGAATCATCCGGGAAGTCAGCCTACAACTCCTTGTAGCAAGTGTTACTGTAAAAAGTGTTGCTATCATTGCCAGCATTGCTTCATAACGAAAGGCTTAGGCATCTCATATGGCAGGAAGAAGCGGAGACAGCGACGAGGACCTCCTCAGAGCAATAAGGATCATCAAAATCCTGTACAAAAGCAGTAAGTATTAGTAATTAATATATGTAATGCAACCTTTAGAAATCTGTTCAATAGTAGGGCTGATAGTAGCCATAATCCTAGCAATAGTTGCGTGGACTATAGTAGGCATAGAAATTAAGAAATTGCTAAGGCAAAAGAAAATAGACAGGTTAATTGAGAGAATAAGAGAAAGAGCAGAAGACAGTGGCAATGAGAGTGATGGGGATACAGAGGAATTGGCAGCACTTGTTGAGATGGGGAACTATGATCCTGGGGATGATATTAATCTGTAGTGCTGTAGATAAATTGTGGGTTACTGTCTATTATGGGGTACCTGTGTGGAAAGATGCAGAGACCACCCTATTTTGTGCATCAGATGCTAAAGCATATGATACAGAAGTGCATAATGTCTGGGCTACACATGCCTGTGTACCCACAGACCCCAACCCACAAGAAGTACTTTTGGGAAATGTGACAGAAGATTTTAACATGTGGAAAAATAACATGGTAGAACAGATGCATACAGATATAATCAGTCTATGGGACCAAAGCCTACAGCCATGTGTAAAGTTAACCCCTCTCTGCGTTACTTTAAATTGTACCAATGTCACTATCACTACCAATGCCACTGACAGTAACAATGCCAGTCTCCAAGACATGGCAAAAGAAATGACAAACTGCTCTTTCAATATGACCACAGAACTAAGGGATAAGAAACAAAGAGTATATTCACTTTTTTATAAACTTGATGTAGTACAAATTAACAGCAATCAAAATAACAGCAGTCAGTATAGATTAATAAATTGTAATACCTCAGCCATTACACAAGCTTGTCCAAAGGTATCCTTTGAGCCAATTCCCATACATTATTGTGCCCCAGCTGGATTTGCAATTCTAAAATGTAATAATAAGGAGTTCAATGGGACGGGTCCATGCAAAAACGTCAGCACAGTACAGTGTACACATGGGATTAAGCCAGTAGTGTCAACTCAATTGTTGTTGAATGGCAGTCTAGCAGAAGAAGAGATAATAGTTAGATCTGAAAATCTCACAAATAATGCTAAAATCATAATAATACAGCTTAATGAGACTGTAAAAATTAATTGTACCAGACCTAACAACAATACAAGGAACAGTATACGTATAGGACCAGGACAAGCATTCTATGCAACAGGTGCCATAACAGGGGATATAAGACAAGCACATTGTAATGTCAGTAGATCAGAATGGAATAAAACTTTACAACAGGTAGCTAAAAAATTAGGAGACCCTCTTAACAAGACAGAAATAATTTTTAAACCACCCTCAGGAGGGGATTTAGAAATTACAACACATAGTTTTAATTGTGGAGGAGAATTTTTCTATTGTAATACATCAGGCCTGTTTAATAGCACTTGGGTAAATGGCAGCAGGGAATCAAATAGCACAGATAATGATACTATAACTCTCCCGTGTAGAATAAAGCAAATTATAAATATGTGGCAGAGAGTAGGACAAGCAATGTATGCCCTTCCCATCCGAGGAGTAATAAGGTGTGAATCAAACATTACAGGATTAATATTAACAAGAGATGGTGGGAATAATACCAGTACAAATGAAACCATCAGACCTGCAGGAGGAGATATGAGGGACAATTGGAGAAGTGAATTATATAAATATAAAGTAGTAAAAATTGAACCACTAGGAGTAGCACCCACCAAGGCAAGGAGAAGAGTGGTGGAGAGAGAAAAGAGAGCAGTTGGAATAGGAGCTGTGTTCCTTGGGTTCTTAGGAGCAGCAGGAAGCGCTATGGGCGCAGCGGCAGCAACGCTGACGGTACAGGCCAGGCAATTATTGTCTGGCATAGTGCAACAGCAAAGCAATTTGCTGAAGGCTATAGAGGCTCAACAGCATCTGTTGAAACTCACGGTCTGGGGCATTAAACAGCTCCAGGCAAGAGTCCTGGCTGTGGAAAGATACCTAAAGGATCAACAGCTCCTAGGAATTTGGGGCTGCTCTGGAAAACTCATCTGCGCCACTAATGTGCCCTGGAACTCTAGTTGGAGTAATAAATCACAGGCAGAAATATGGCAGAATATGACCTGGCTGCAATGGGATAAAGAAATTGACAATTACACACAAATAATATATATGCTGCTTGAAGAACCACAAAACCAGCAGGAAAAAAATGAACAAGACTTATTGGCATTGGACAAGTGGGGAAGTTTGTGGAATTGGTTTGAGATATCAAAATGGCTGTGGTATATAAGAATATTTATAATGATAGTAGGAGGCTTAATAGGATTAAGAATAGTTTTTGCTGTGCTTTCTGTAATAAATAGAGTTAGGCAGGGATACTCACCTCTATCGTTTCAGACCCATACCCCAAACCCAGAGGGAGTCGACAGGCCCGGAAGAATCGAAGAAGAAGGTGGAGAGCAAGGCAGAGACAGATCGATTCGATTAGTCAGCGGATTCTTAGCACTTGCCTGGGACGATCTGAGGAGCCTGTGCCTCTTCAGCTACCACCGCTTGAGAGACTTAATCTTGATTGCTGCGAGGATTGTGGAACTTCTGGGACGCAGGGGGTGGGAAGCAATCAAATATCTGTGGAATCTCCTGCAGTATTGGATTCAGGAACTAAAGAATAGTGCTATTAACTTGTTTAATACCATAGCAATAGCAGTAGCTGAGGGAACAGATAGGGTTATAGAAATAGGACAAAGAATTGGTAGGGCTATCCTCAACACACCTAGAAGAATAAGACAGGGCTTGGAAAGGGCTTTGCTATAAAATGGGTGGCAAATGGTTAAAAAGTAGTATAGTAGGATGGCCTGCTGTAAGAGAAAGAATAAGACGAACTGAGCCAGCAGCAGAGGGAGTAGGAGCAGCGTCTCAAGACTTAGATAAATATGGGGCACTGACAAGCAGCAACACAGTCACCAATAATCCTGATTGTGCCTGGCTGGAAGCGCAAAAGGAGGAAGAGGAGGTAGGCTTTCCAGTCAGACCACAAGTACCTTTAAGACCAATGACTTATAAGGCAGCAGTCGATCTCAGCTTCTTTTTAAAAGAAAAGGGGGGACCGGAAGGGTTAATTTACTCTAAGAAAAGGCAAGACATCCTTGATTTGTGGGTCTATAACACACAAGGCTTCTTCCCTGATTGGCAAAACTACACACCAGGACCAGGGACCAGATATCCCCTGACCTTCGGATGGTGCTTCAAGCTAGTGCCAGTTGACCCAAGGGAAGTAGAAGAGGCCAATGAAGGAGAGAACAACTGCTTGCTACACCCTATGAGTCAGCATGGAATAGAGGATGAAGACAAAGAAGTATTAAGGTGGAAGTTTGACAGTCAGCTAGCACGCAGACACATGGCCCGCGAGATGCATCCGGAGTATTACAAAGACTGCTGACACAGGAGTTGCAAAGACTGCTAACACAGGAGTTGCTGACAGGGACTTTCTGCAAGGGACTTTCCAGGGGAGGTGTGGTTTGGGCGGAGTTGGGGAGTGGCTAACCCTCAGATGCTGCATATAAGCAGCTGCTTTTCGCTTGTACTGGGTCTCTCTTGTTAGACCAGATCGAGCCTGGGAGCTCTCTGGCTAGCTAGGGAACCCACTGCTTAA'\r\n","predict(seq_A1CD)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3, 7500)\n","k: 1 MOVE_WINDOW: 1 READ_LENGTH: 7500 \n","Pred_class: A1\n","(1, 8934)\n","WARNING:tensorflow:Model was constructed with shape (None, 14805) for input KerasTensor(type_spec=TensorSpec(shape=(None, 14805), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 8934).\n","k: 21 MOVE_WINDOW: 0 READ_LENGTH: 0 \n","Pred_class: BF1\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'A1'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"fVD4nE1T5sPV","executionInfo":{"status":"ok","timestamp":1608533770312,"user_tz":-360,"elapsed":8035,"user":{"displayName":"L Lawlight","photoUrl":"","userId":"13905760247926160423"}},"outputId":"2af194fb-ab35-4cc5-cbcc-fbfaa0d3a29f"},"source":["pip install anvil-uplink\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting anvil-uplink\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/e7/4eb5859dd68eab5baf07e91e38eebd0fa7fa87aef4f2ebc5ca00490c8bbc/anvil_uplink-0.3.34-py2.py3-none-any.whl (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.4MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from anvil-uplink) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from anvil-uplink) (1.15.0)\n","Collecting ws4py\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/20/4019a739b2eefe9282d3822ef6a225250af964b117356971bd55e274193c/ws4py-0.5.1.tar.gz (51kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n","\u001b[?25hCollecting argparse\n","  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n","Building wheels for collected packages: ws4py\n","  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ws4py: filename=ws4py-0.5.1-cp36-none-any.whl size=45216 sha256=1e0ff7b4012df1b9fa8a3d1a05e18fb675cbad5a6069745f4774d07f531b19c7\n","  Stored in directory: /root/.cache/pip/wheels/a2/6e/4e/8b0ae12fb9b8a05715256952cf7609a8ab86285fab99b88c68\n","Successfully built ws4py\n","Installing collected packages: ws4py, argparse, anvil-uplink\n","Successfully installed anvil-uplink-0.3.34 argparse-1.4.0 ws4py-0.5.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse","google"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"QDWkbCcLBZPw"},"source":["\r\n","import anvil.server\r\n","\r\n","anvil.server.connect(\"GSJPSCRUUB7KWMF5ANAVGKXB-MM7YG5X64D2CE5HT\")\r\n","newnames={'B': 5727, 'C': 2077, '01_AE': 1426, 'A1': 498, '01B': 210, \r\n","                    '02_AG': 168, 'BF1': 143, 'A6': 117, 'A1C': 111, 'G': 96, 'BC': 95, \r\n","                    'A1D': 94, 'AD': 94, 'D': 87, 'F1': 82, 'A1CD': 62, 'CD': 61, 'O': 57,\r\n","                    '0107': 57, '01BC': 50, '07_BC': 41, '08_BC': 35, '02A1': 29, \r\n","                    '11_cpx': 25, '35_AD': 22}\r\n","\r\n","key_list=list(newnames)\r\n","##will need to get the subtype label.. later\r\n","\r\n","@anvil.server.callable\r\n","##define the predict function above. under this @ line.\r\n","\r\n","def predict(seq):\r\n","    newnames={'B': 5727, 'C': 2077, '01_AE': 1426, 'A1': 498, '01B': 210, \r\n","                    '02_AG': 168, 'BF1': 143, 'A6': 117, 'A1C': 111, 'G': 96, 'BC': 95, \r\n","                    'A1D': 94, 'AD': 94, 'D': 87, 'F1': 82, 'A1CD': 62, 'CD': 61, 'O': 57,\r\n","                    '0107': 57, '01BC': 50, '07_BC': 41, '08_BC': 35, '02A1': 29, \r\n","                    '11_cpx': 25, '35_AD': 22}\r\n","    types = list(newnames.keys())\r\n","    k = [1,21,15]\r\n","    MOVE_WINDOW = [1,0,0]\r\n","    READ_LEN = [7500,0,1000]\r\n","    JUMP=[400,400,400]\r\n","    NUM_MODELS = len(k)\r\n","    saved_models = {\r\n","            '117500':'/content/drive/MyDrive/ML 472/Data/Models/kmer_model_k_1_sliding.h5',\r\n","            '2100':'/content/drive/MyDrive/ML 472/Data/Models/kmer_model_k21_readWhole.h5',\r\n","            '1501000':'/content/drive/MyDrive/ML 472/Data/Models/kmer_model_k15_read1000.h5'\r\n","    }\r\n","    saved_tokenizers = {\r\n","            '117500':'/content/drive/MyDrive/ML 472/Data/Models/tokenizer.pickle',\r\n","            '2100':'/content/drive/MyDrive/ML 472/Data/Models/tokenizer_k21_readWhole.pickle',\r\n","            '1501000':'/content/drive/MyDrive/ML 472/Data/Models/tokenizer_k15_read1000.pickle'\r\n","    }\r\n","    predictions = []\r\n","    str_pred = ''\r\n","    for i in range(NUM_MODELS):\r\n","        s = str(k[i])+str(MOVE_WINDOW[i])+str(READ_LEN[i])\r\n","        \r\n","        #Loading the saved model\r\n","        MODEL_PATH = saved_models[s]\r\n","        \r\n","        #Loading saved tokenizer \r\n","        TOKENIZERPATH = saved_tokenizers[s]\r\n","        \r\n","        # Preprocessing the newly provided seq\r\n","        type_texts = process_seq(seq,k[i],MOVE_WINDOW[i],READ_LEN[i],JUMP[i])\r\n","        \r\n","        with open(TOKENIZERPATH, 'rb') as handle:\r\n","            tokenizer = pickle.load(handle)\r\n","            max_length = pickle.load(handle)\r\n","        tokenizer.fit_on_texts(type_texts)\r\n","        encoded_docs = tokenizer.texts_to_sequences(type_texts)\r\n","        max_length = max([len(s.split()) for s in type_texts])\r\n","        X = pad_sequences(encoded_docs, maxlen = max_length, padding = 'post')\r\n","        print(X.shape)\r\n","        loaded_model = load_model(MODEL_PATH)\r\n","        y_pred = np.array(loaded_model.predict_classes(X))\r\n","        counts = np.bincount(y_pred)\r\n","        subtype_ = np.argmax(counts)\r\n","        print('k:',k[i],'MOVE_WINDOW:',MOVE_WINDOW[i],'READ_LENGTH:',READ_LEN[i],'\\nPred_class:',types[subtype_])\r\n","        predictions.append(types[subtype_])\r\n","        str_pred+='k:'+str(k[i])+' MOVE_WINDOW:'+str(MOVE_WINDOW[i])+' READ_LENGTH:'+str(READ_LEN[i])+'\\nPred_class:'+types[subtype_]+'\\n'\r\n","    print(predictions)\r\n","    return str_pred\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EAa37kYQlxd","outputId":"5f4121ec-4683-4684-8f71-14232e83ee3d"},"source":["anvil.server.wait_forever()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(4, 7500)\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f15d8fba1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","k: 1 MOVE_WINDOW: 1 READ_LENGTH: 7500 \n","Pred_class: B\n","(1, 9166)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6P_UgWszdzEt"},"source":[""],"execution_count":null,"outputs":[]}]}